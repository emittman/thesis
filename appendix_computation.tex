\chapter{ADDITIONAL MATERIAL FOR CHAPTER 1}

\section*{CUDA libraries}
There are several libraries that make implementing these algorithms easier in CUDA. Thrust \citep{thrust} extends many concepts from the C++ Standard Template Library to Nvidia GPUs. Included are several useful generic algorithms:
\begin{itemize}
\item \code{thrust::for\_each}: This algorithm accepts a functor (an
  instance of a class with a member \code{operator()} function)
  and an iterator. The serial version increments the iterator, passing
  each element to the \code{operator()} in turn. The parallel implementation
  produces the same results, only in thread parallel fashion. The
  \code{thrust::zip\_iterator} is very useful, as it can be used
  to iterate
  over a \code{thrust::tuple}. This approach is very general, allowing
  for operations involving up to ten variables using an SoA
  design.

\item \code{thrust::reduce/reduce\_by\_key}: As described in section
  \ref{sec:parallel}, both reduce and cumulative sum are defined for any associative binary operators. Reduce by key accepts a key argument and a compatible binary predicate that identifies changes in the key. For example, for the binary predicate \code{x == y}, the key \code{\{1,1,1,2,2,1\}} would have the result be three quantities, the reductions of the first three values, the next two and the last, respectively.

\item \code{thrust::inclusive/exclusive\_scan/scan\_by\_key}: Thrust
  offers multiple versions of scan, which is another term for cumulative sum. The exclusive
  version results in the array element, $a_i$, containing the sum $s_{i-1}$ (excluding the value $v_i$, while the inclusive version leaves $a_i$ containing $s_i$.
\end{itemize}

For linear algebra on the GPU, standard installations of CUDA also
include CUBLAS \cite{cublas}. CUBLAS has implementions of BLAS/LAPACK
routines optimized for the GPU. Typically, calls to the CUBLAS
functions are initiated by the CPU and act on device memory (host
API). For newer GPUs (compute 3.5 and later), there are routines that
can be initiated within a kernel (device API). From the host API, our
algorithm uses \code{cublasDgemm} for multiplying large matrices in
device memory. From the
device API, our algorithm uses \code{cublasDtrsv} to solve many small triangular
systems of equations in parallel.

Schemes for parallel pseudo-random number generation (PRNG) have been
developed for CUDA. Since PRNGs are deterministic and sequential, a
natural parallel adaptation is access the same sequence at locations
distant enough to avoid overlap or to use a strided access
pattern. CURAND \cite{curand}, provides such functionality for generating
normal and uniform random numbers on the GPU. For other distributions,
such as gamma,
one can write a custom kernel, making use of CURAND as a source of
randomness, for threaded sampler.